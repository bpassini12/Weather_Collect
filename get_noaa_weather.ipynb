{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOAA\n",
    "- request example: https://www.ncei.noaa.gov/access/services/data/v1?dataset=local-climatological-data&dataTypes=HourlyWindSpeed&dataTypes=HourlyDryBulbTemperature&stations=72530094846&startDate=2018-05-01&endDate=2018-05-31\n",
    "- list of stationsids: https://www.itl.nist.gov/div898/winds/asos-wx/WBAN-MSC.TXT\n",
    " - list of WBAN and lat/long: https://www.epa.gov/sites/default/files/documents/STATION_LOCATIONS.PDF\n",
    "- Other Notes: https://www.ncei.noaa.gov/access/services/support/v3/datasets.json\n",
    "\n",
    "- Fort Bend WBAN: 12977\n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed to make web requests\n",
    "import requests\n",
    "#store the data we get as a dataframe\n",
    "import pandas as pd\n",
    "#for storing and pulling data\n",
    "import bp_sql as bp\n",
    "#mathematical operations on lists\n",
    "import numpy as np\n",
    "#parse the datetimes we get from NOAA\n",
    "import datetime\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Station Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tday = datetime.datetime.today().replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "tday_str = tday.strftime('%m-%d-%Y')\n",
    "\n",
    "db_name = 'weather.db'\n",
    "conn = bp.create_connection(db_name)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "download_fldr = os.path.join(cwd, 'downloads')\n",
    "\n",
    "\n",
    "sql_create_awsmcs_wban = ''' Create Table if not exists wban_stations (\n",
    "                                    AWSMSC text,\n",
    "                                    WBAN text,\n",
    "                                    NAME text,\n",
    "                                    AWSMSC_WBAN text\n",
    "                                    );\n",
    "                                '''\n",
    "\n",
    "\n",
    "bp.create_table(db_name, sql_create_awsmcs_wban)\n",
    "\n",
    "\n",
    "# pull from database table or else repull from website and load into db\n",
    "try:\n",
    "    awsmcs_wban_df = pd.read_sql_query(con=conn, sql='Select* from wban_stations')\n",
    "\n",
    "except sqlite3.OperationalError:\n",
    "\n",
    "\n",
    "    # sites\n",
    "    stations_link = 'https://www.itl.nist.gov/div898/winds/asos-wx/WBAN-MSC.TXT'\n",
    "\n",
    "    # read in html byte\n",
    "    i = requests.get(stations_link)\n",
    "    content = i.content\n",
    "    decoded_content  = str(content,'UTF-8')\n",
    "\n",
    "    end_list = []\n",
    "\n",
    "    #skip first 6 rows since it doesn't contain actual data\n",
    "    #read cols in first then create list with all data\n",
    "    #Couldnt pd.read_csv bc some of the names are 3+ words and it would skip the >2+ NAMEs\n",
    "    for n,i in enumerate(decoded_content.splitlines()[6:]):\n",
    "        if n ==0:\n",
    "            cols = list(i.split())\n",
    "        else:\n",
    "            nums = i.split()[0:2]\n",
    "            names = \" \".join(i for i in i.split()[2:])\n",
    "            \n",
    "            nums.append(names)\n",
    "\n",
    "            end_list.append(nums)\n",
    "\n",
    "    awsmcs_wban_df = pd.DataFrame(end_list, columns=cols)\n",
    "    awsmcs_wban_df = awsmcs_wban_df[awsmcs_wban_df['NAME'].notna()]\n",
    "    sl_data = pd.DataFrame({'AWSMSC':['720637'],'WBAN':['00223'],'NAME':'SUGAR LAND REGIONAL AIRPORT'})\n",
    "    awsmcs_wban_df = pd.concat([awsmcs_wban_df, sl_data])\n",
    "    awsmcs_wban_df['AWSMSC_WBAN'] = awsmcs_wban_df['AWSMSC'] + awsmcs_wban_df['WBAN']\n",
    "\n",
    "    awsmcs_wban_df.to_sql(name='wban_stations', con=conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Houston Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWSMSC</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>AWSMSC_WBAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722429</td>\n",
       "      <td>53910</td>\n",
       "      <td>HOUSTON HOOKS MEMORIAL AP</td>\n",
       "      <td>72242953910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722430</td>\n",
       "      <td>12960</td>\n",
       "      <td>HOUSTON INTERCONTINENTAL AP</td>\n",
       "      <td>72243012960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>722433</td>\n",
       "      <td>12969</td>\n",
       "      <td>HOUSTON LAKESIDE ARP</td>\n",
       "      <td>72243312969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722435</td>\n",
       "      <td>12918</td>\n",
       "      <td>HOUSTON WILLIAM P HOBBY AP</td>\n",
       "      <td>72243512918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722436</td>\n",
       "      <td>12906</td>\n",
       "      <td>HOUSTON ELLINGTON AFB</td>\n",
       "      <td>72243612906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AWSMSC   WBAN                         NAME  AWSMSC_WBAN\n",
       "0  722429  53910    HOUSTON HOOKS MEMORIAL AP  72242953910\n",
       "1  722430  12960  HOUSTON INTERCONTINENTAL AP  72243012960\n",
       "2  722433  12969         HOUSTON LAKESIDE ARP  72243312969\n",
       "3  722435  12918   HOUSTON WILLIAM P HOBBY AP  72243512918\n",
       "4  722436  12906        HOUSTON ELLINGTON AFB  72243612906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hou_stations_df = awsmcs_wban_df[awsmcs_wban_df.NAME.str.contains('HOUSTON')].reset_index(drop=True)\n",
    "hou_stations_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrly_station_wx(awsmcs_wban, strt_dte, end_dte):\n",
    "   '''Pulls hourly weather from NOAA Api'''\n",
    "\n",
    "   try:\n",
    "      os.makedirs(download_fldr)\n",
    "   except FileExistsError:\n",
    "      # directory already exists\n",
    "      pass\n",
    "\n",
    "   vars_dict = {'HourlyAltimeterSetting': 'float',\n",
    "         'HourlyDewPointTemperature': 'int',\n",
    "         'HourlyDryBulbTemperature': 'int',\n",
    "         'HourlyPrecipitation': 'float',\n",
    "         'HourlyPressureChange': 'float',\n",
    "         'HourlyPressureTendency': 'int',\n",
    "         'HourlyRelativeHumidity': 'int',\n",
    "         'HourlySeaLevelPressure': 'float',\n",
    "         'HourlyStationPressure': 'float',\n",
    "         'HourlyVisibility': 'float',\n",
    "         'HourlyWetBulbTemperature': 'int',\n",
    "         'HourlyWindDirection': 'int',\n",
    "         'HourlyWindGustSpeed': 'int',\n",
    "         'HourlyWindSpeed': 'int'}\n",
    "\n",
    "   hrly_vars = list(vars_dict.keys())\n",
    "\n",
    "   hrly_vars_str = '&dataTypes='.join(hrly_vars)\n",
    "\n",
    "   noaa_api_call = f'''https://www.ncei.noaa.gov/access/services/data/v1?dataset=local-climatological-data&dataTypes={hrly_vars_str}&stations={awsmcs_wban}&startDate={strt_dte}&endDate={end_dte}'''\n",
    "   print(noaa_api_call)\n",
    "   station_name = awsmcs_wban_df[awsmcs_wban_df.AWSMSC_WBAN==awsmcs_wban]['NAME'].iloc[0]\n",
    "\n",
    "   filename = f'{station_name}_{strt_dte}_{end_dte}.csv'\n",
    "   with open(os.path.join(download_fldr, filename), 'wb') as file:\n",
    "      response = requests.get(noaa_api_call, allow_redirects=True)\n",
    "      file.write(response.content)\n",
    "\n",
    "   # get filepath and readin csv\n",
    "   filepath = os.path.join(download_fldr,filename) \n",
    "\n",
    "   df = pd.read_csv(filepath)\n",
    "\n",
    "   # column formatting\n",
    "   df['DATE'] = pd.to_datetime(df.DATE)\n",
    "\n",
    "   # get a list of all non-main columns that are also object datatypes\n",
    "   # all should be numeric but sometimes they have random strings in them, so the str needs to be removed\n",
    "   object_var_cols = list(set(df.select_dtypes(include=['object']).columns).intersection(set(hrly_vars)))\n",
    "\n",
    "   # remove any strings from these variable columns because they shouldnt have any strings in them\n",
    "   df[object_var_cols] = df[object_var_cols].replace(r'[^\\d.]+', '',regex=True)\n",
    "\n",
    "   #fill NaNs and change to ints\n",
    "   df[hrly_vars] = df[hrly_vars].fillna(0)\n",
    "   df[hrly_vars] = df[hrly_vars].replace('','0')\n",
    "   df = df.astype(vars_dict)\n",
    "\n",
    "   df.insert(1,'STATION_NAME', station_name)\n",
    "   df.columns = df.columns.str.lower()\n",
    "\n",
    "   # sort and keep the last\n",
    "   df = df[df.report_type.isin(['FM-12','FM-15','FM-16'])].reset_index(drop=True)\n",
    "   df['source'] = df.source.astype(int)\n",
    "   df.sort_values(by='source', ascending=True, inplace=True)\n",
    "   df.drop_duplicates(keep='last', subset=['station','date'],inplace=True)\n",
    "\n",
    "   return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = pd.concat([hrly_station_wx(awsmcs_wban=i,strt_dte='2020-01-01',end_dte='2023-12-31') for i in hou_stations_df.AWSMSC_WBAN])\n",
    "x = x[x.report_type.isin(['FM-12','FM-15','FM-16'])].reset_index(drop=True)\n",
    "x['source'] = x.source.astype(int)\n",
    "x.sort_values(by='source', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awsmcs_wban_df[awsmcs_wban_df.NAME.str.contains('SUGAR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ncei.noaa.gov/access/services/data/v1?dataset=local-climatological-data&dataTypes=HourlyAltimeterSetting&dataTypes=HourlyDewPointTemperature&dataTypes=HourlyDryBulbTemperature&dataTypes=HourlyPrecipitation&dataTypes=HourlyPressureChange&dataTypes=HourlyPressureTendency&dataTypes=HourlyRelativeHumidity&dataTypes=HourlySeaLevelPressure&dataTypes=HourlyStationPressure&dataTypes=HourlyVisibility&dataTypes=HourlyWetBulbTemperature&dataTypes=HourlyWindDirection&dataTypes=HourlyWindGustSpeed&dataTypes=HourlyWindSpeed&stations=72063700223&startDate=1980-01-01&endDate=2023-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_940/2502798668.py:41: DtypeWarning: Columns (4,5,6,12,13,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "sl =hrly_station_wx(awsmcs_wban='72063700223',strt_dte='1980-01-01',end_dte='2023-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_create_hrly_wx = ''' Create Table if not exists hrly_wx (\n",
    "                                    STATION text,\n",
    "                                    STATION_NAME text,\n",
    "                                    DATE text,\n",
    "                                    REPORT_TYPE text,\n",
    "                                    SOURCE integer,\n",
    "                                    HOURLYALTIMETERSETTING real,\n",
    "                                    HOURLYDEWPOINTTEMPERATURE integer,\n",
    "                                    HOURLYDRYBULBTEMPERATURE integer,\n",
    "                                    HOURLYPRECIPITATION real,\n",
    "                                    HOURLYPRESSURECHANGE real,\n",
    "                                    HOURLYPRESSURETENDENCY integer,\n",
    "                                    HOURLYRELATIVEHUMIDITY integer,\n",
    "                                    HOURLYSEALEVELPRESSURE real,\n",
    "                                    HOURLYSTATIONPRESSURE real,\n",
    "                                    HOURLYVISIBILITY real,\n",
    "                                    HOURLYWETBULBTEMPERATURE integer,\n",
    "                                    HOURLYWINDDIRECTION integer,\n",
    "                                    HOURLYWINDGUSTSPEED integer,\n",
    "                                    HOURLYWINDSPEED integer\n",
    "                                    );\n",
    "                                '''\n",
    "\n",
    "bp.create_table(db_name, sql_create_hrly_wx)\n",
    "\n",
    "# creates \n",
    "bp.create_table(db_name, 'CREATE UNIQUE INDEX if not exists ux_hrly_wban_wthr ON hrly_wx(STATION, STATION_NAME, DATE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn to db\n",
    "\n",
    "db_name = 'weather.db'\n",
    "conn = bp.create_connection(db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type               name       tbl_name  rootpage  \\\n",
      "0  table            hrly_wx        hrly_wx         2   \n",
      "1  table      wban_stations  wban_stations         3   \n",
      "2  index  ux_hrly_wban_wthr        hrly_wx        29   \n",
      "\n",
      "                                                 sql  \n",
      "0  CREATE TABLE hrly_wx (\\n                      ...  \n",
      "1  CREATE TABLE wban_stations (\\n                ...  \n",
      "2  CREATE UNIQUE INDEX ux_hrly_wban_wthr ON hrly_...  \n"
     ]
    }
   ],
   "source": [
    "bp.select_db_master_tbl(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp_venv",
   "language": "python",
   "name": "bp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb531205692794cc84d126eeee25e07db4c0459ba8c70ae9f2a86b110ee6a676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
